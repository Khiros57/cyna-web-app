README.md

![Build & Deploy](https://github.com/Khiros57/cyna-web-app/actions/workflows/deploy.yaml/badge.svg)

------

## ğŸ” RecrÃ©ation du cluster Kubernetes SKS (Exoscale)

Ce projet suppose que vous dÃ©ployez un site vitrine sur un cluster SKS Exoscale. Voici les commandes officielles (inspirÃ©es de la documentation Exoscale) pour recrÃ©er un cluster complet.

### ğŸ“ Zone : `de-fra-1`

### 1. CrÃ©er le cluster SKS
```bash
exo compute sks create cluster-cyna \
    --zone de-fra-1 \
    --service-level pro \
    --nodepool-name cyna-nodepool \
    --nodepool-size 3 \
    --nodepool-security-group sks-security-group
```
###The Exoscale orchestrator then creates a new instance pool with 3 instances on your behalf. By default, the instances sizes are Medium instances with 50 GB disks attached.

### 2. Ajouter un nodepool (3 nÅ“uds standard)(optionnel si la prÃ©cÃ©dente commande par dÃ©faut crÃ©e 3 instances dans le noeud)
```bash
exo --zone de-fra-1 compute sks nodepool add cluster-cyna \
  --name cyna-nodepool \
  --instance-type standard.small \
  --size 3
```

### 3. RÃ©cupÃ©rer le kubeconfig pour `kubectl`
```bash
mkdir -p ~/.kube
exo compute sks kubeconfig cluster-cyna kube-admin \
    --zone de-fra-1 \
    --group system:masters > ~/.kube/config
chmod 600 ~/.kube/config
```

### 4. Tester l'accÃ¨s au cluster
```bash
kubectl get nodes
```

â¡ï¸ Une fois ces Ã©tapes effectuÃ©es, un `git push` vers la branche `main` dÃ©clenche le dÃ©ploiement automatique via GitHub Actions (`.github/workflows/deploy.yaml`).

------

## ğŸ›‘ ArrÃªt et suppression du cluster Exoscale

Pour Ã©viter toute facturation inutile, vous pouvez supprimer proprement votre cluster SKS.

### 1. Lister les nodepools
```bash
exo --zone de-fra-1 compute sks nodepool list cluster-cyna
```

### 2. Supprimer les nodepools (exemple avec "cyna-nodepool")
```bash
exo --zone de-fra-1 compute sks nodepool delete cluster-cyna cyna-nodepool
```

### 3. Supprimer le cluster SKS
```bash
exo --zone de-fra-1 compute sks delete cluster-cyna
```

âœ… Ces Ã©tapes libÃ¨rent les ressources (VMs, volumes, IP) et arrÃªtent la facturation liÃ©e au cluster.
